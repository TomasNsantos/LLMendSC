# üîê LLMendSC: Corre√ß√£o Assistida por LLM para Vulnerabilidades em Smart Contracts

---

## üéØ Objetivo

Este projeto prop√µe a extens√£o do **SmartGuard**, um framework baseado em LLMs para detec√ß√£o de vulnerabilidades em contratos inteligentes, com um m√≥dulo adicional de **reparo autom√°tico assistido por LLM**. A ideia √© que, ao identificar falhas como *reentr√¢ncia*, *overflow* ou *timestamp dependence*, o sistema sugira corre√ß√µes plaus√≠veis e seguras, reduzindo o ciclo de feedback e aumentando a automa√ß√£o na manuten√ß√£o de smart contracts.

---

## üóâ Atividade do Ciclo de Vida Envolvida

**Manuten√ß√£o e Corre√ß√£o de Software** ‚Äì atividade cr√≠tica para garantir a seguran√ßa e a confiabilidade de sistemas em produ√ß√£o. Este projeto explora como **LLMs podem atuar n√£o apenas como detectores, mas como agentes de reparo automatizado**, com apoio de valida√ß√£o formal para garantir corre√ß√µes seguras e funcionais.

---

## ü§ñ Proposta com LLM

Ao detectar uma vulnerabilidade em um contrato Solidity por meio do SmartGuard, um LLM (como GPT-4, Claude 3 ou LLaMA 3) recebe o trecho vulner√°vel e o contexto, e sugere uma vers√£o reparada do c√≥digo.  
Essa sugest√£o √© ent√£o validada por ferramentas de an√°lise est√°tica (como **Slither** ou **Mythril**) e por testes de compila√ß√£o e execu√ß√£o, com o objetivo de garantir que:

- A vulnerabilidade foi de fato corrigida;
- O c√≥digo permanece funcional e semanticamente equivalente;
- N√£o foram introduzidos novos problemas.

---

## üß™ Experimentos



### ‚úÖ Vantagens (Precis√£o e Automa√ß√£o)

**Cen√°rio:** Conjunto de contratos com falhas conhecidas.  
**M√©todo A (Controle):** Apenas detec√ß√£o com SmartGuard.  
**M√©todo B (Experimental):** Detec√ß√£o com SmartGuard + reparo automatizado com LLM + valida√ß√£o.  
**M√©tricas:**

- % de vulnerabilidades corrigidas corretamente (sem falso positivo/negativo);
- Taxa de sucesso na compila√ß√£o do c√≥digo corrigido;
- Compara√ß√£o manual ou automatizada da l√≥gica preservada.

### ‚ö†Ô∏è Limita√ß√µes (Robustez e Generaliza√ß√£o)

- Testes com vulnerabilidades mais raras ou fora das 3 principais categorias;
- Avalia√ß√£o do impacto da escolha do LLM (ex: GPT-3.5 vs GPT-4o);
- Avalia√ß√£o da capacidade de reparo em c√≥digos maiores ou com l√≥gica mais complexa.

---

## üë• Equipe

- Tom√°s Nascimento Santos ([tns](https://github.com/TomasNsantos))
- [Seu Nome 2] (`username2`)  
- [Seu Nome 3] (`username3`)  
- [Seu Nome 4] (`username4`)  

Este projeto √© parte da disciplina de TAES, com o objetivo de investigar contribui√ß√µes pr√°ticas da IA generativa para atividades do ciclo de vida do software.

---

## üîê Configura√ß√£o da API da OpenAI (Uso Seguro)

Este projeto utiliza a API da OpenAI para realizar tarefas de detec√ß√£o e reparo de vulnerabilidades. Para garantir seguran√ßa e boas pr√°ticas:

### ‚úÖ 1. **Nunca exponha sua chave no c√≥digo**

Jamais insira sua chave diretamente no c√≥digo Python. Use vari√°veis de ambiente via `.env`.

### ‚öôÔ∏è 2. Como configurar sua chave localmente

```python
#### a) Crie um arquivo `.env` na raiz do projeto:


cp .env.example .env


#### b) Adicione sua chave real no .env

OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_API_BASE=https://api.openai.com/v1

#### c) Rode o projeto normalmente
 O carregamento da chave √© feito automaticamente via config.py


